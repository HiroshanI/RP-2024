{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":1956405,"sourceType":"datasetVersion","datasetId":1060121},{"sourceId":7563141,"sourceType":"datasetVersion","datasetId":4403839},{"sourceId":7917880,"sourceType":"datasetVersion","datasetId":4652490},{"sourceId":8122196,"sourceType":"datasetVersion","datasetId":4799443}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom torch.nn.parallel import DataParallel\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T09:24:15.102684Z","iopub.execute_input":"2024-04-18T09:24:15.103091Z","iopub.status.idle":"2024-04-18T09:24:17.559026Z","shell.execute_reply.started":"2024-04-18T09:24:15.103065Z","shell.execute_reply":"2024-04-18T09:24:17.557373Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/emotions/text.csv\")\ndisplay(df.head())\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:17.561465Z","iopub.execute_input":"2024-04-18T09:24:17.562581Z","iopub.status.idle":"2024-04-18T09:24:19.499498Z","shell.execute_reply.started":"2024-04-18T09:24:17.562526Z","shell.execute_reply":"2024-04-18T09:24:19.496221Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/emotions/text.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.500451Z","iopub.status.idle":"2024-04-18T09:24:19.500883Z","shell.execute_reply.started":"2024-04-18T09:24:19.500676Z","shell.execute_reply":"2024-04-18T09:24:19.500692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('label').apply(lambda x: x.sample(1000), include_groups=False)\nnew_df = pd.DataFrame(columns=['text', 'label'])\nfor label in df.label.unique():\n    sample_df = df[df.label == label].sample(14972)\n    new_df = pd.concat([new_df, sample_df], ignore_index=True)\nnew_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.502288Z","iopub.status.idle":"2024-04-18T09:24:19.502661Z","shell.execute_reply.started":"2024-04-18T09:24:19.502490Z","shell.execute_reply":"2024-04-18T09:24:19.502504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = AutoModel.from_pretrained(\"bert-base-uncased\")\n\ntrain_X, val_X, train_y, val_y = train_test_split(new_df[\"text\"], \n                                                  new_df[\"label\"], \n                                                  test_size=0.2, \n                                                  random_state=42)\n\ntrain_X = train_X.tolist()\nval_X = val_X.tolist()\ntrain_y = np.array(train_y, dtype=np.float64)\nval_y = np.array(val_y, dtype=np.float64)\n\ntrain_encodings = tokenizer(train_X, truncation=True, \n                            padding=True, max_length=128, \n                            return_tensors='pt')\nval_encodings = tokenizer(val_X, truncation=True, \n                          padding=True, max_length=128, \n                          return_tensors='pt')\n\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], \n                                               train_encodings['attention_mask'], \n                                               torch.tensor(train_y,dtype=torch.float64))\nval_dataset = torch.utils.data.TensorDataset(val_encodings['input_ids'], \n                                             val_encodings['attention_mask'], \n                                             torch.tensor(val_y,dtype=torch.float64))\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.503880Z","iopub.status.idle":"2024-04-18T09:24:19.504209Z","shell.execute_reply.started":"2024-04-18T09:24:19.504052Z","shell.execute_reply":"2024-04-18T09:24:19.504065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_samples = iter(train_dataloader)\ntexts, _, labels = next(training_samples)\ntexts","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.505032Z","iopub.status.idle":"2024-04-18T09:24:19.505382Z","shell.execute_reply.started":"2024-04-18T09:24:19.505203Z","shell.execute_reply":"2024-04-18T09:24:19.505217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EmotionClassifier(nn.Module):\n    def __init__(self, transformer_model, num_classes):\n        super(EmotionClassifier, self).__init__()\n        self.transformer = transformer_model\n        self.fc = nn.Linear(768, num_classes)  \n        \n    def forward(self, input_ids, attention_mask):\n        output = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = output.pooler_output \n        logits = self.fc(pooled_output)\n        return logits\n    \nnum_classes = 6\nnum_epochs = 3\nlearning_rate = 1e-5\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nmodel = EmotionClassifier(model, num_classes)\nmodel = DataParallel(model)\nmodel = model.to(device)\nprint(model)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()\nprint(optimizer)\nprint(criterion)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.506346Z","iopub.status.idle":"2024-04-18T09:24:19.506675Z","shell.execute_reply.started":"2024-04-18T09:24:19.506509Z","shell.execute_reply":"2024-04-18T09:24:19.506522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n    total_correct = 0\n    \n    # Training loop\n    print(f\"----- Epoch {epoch+1} [Training] -----\")\n    for i, batch in enumerate(train_dataloader):\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n       \n        labels = labels.to(device).long()\n        outputs = outputs.float()\n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total_correct += (predicted == labels).sum().item()\n        \n        if i%100 == 0:\n            print(f\"Batch: {i:4d}  |  Loss: {loss.item():.4f}\")\n    \n    train_loss = total_loss / len(train_dataloader)\n    train_accuracy = total_correct / len(train_dataset)\n    \n    # Validation loop\n    model.eval()\n    total_val_loss = 0.0\n    total_val_correct = 0\n    val_predicted = []\n    val_labels = []\n\n    print(f\"----- Epoch {epoch+1} [Validation] -----\")\n    with torch.no_grad():\n        for i, batch in enumerate(val_dataloader):\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            outputs = model(input_ids, attention_mask)\n            labels = labels.to(device).long()\n\n            outputs = outputs.float()\n            loss = criterion(outputs, labels)\n\n            total_val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total_val_correct += (predicted == labels).sum().item()\n            val_predicted.extend(predicted.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n            \n            if i%100 == 0:\n                print(f\"Batch: {i:3d}  ->  Loss: {loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.507708Z","iopub.status.idle":"2024-04-18T09:24:19.508044Z","shell.execute_reply.started":"2024-04-18T09:24:19.507882Z","shell.execute_reply":"2024-04-18T09:24:19.507896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nval_predicted = np.array(val_predicted)\nval_labels = np.array(val_labels)\n\nprint(classification_report(val_labels, val_predicted, target_names=[f'Class {i}' for i in range(num_classes)]))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.509223Z","iopub.status.idle":"2024-04-18T09:24:19.509910Z","shell.execute_reply.started":"2024-04-18T09:24:19.509721Z","shell.execute_reply":"2024-04-18T09:24:19.509737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.510922Z","iopub.status.idle":"2024-04-18T09:24:19.511579Z","shell.execute_reply.started":"2024-04-18T09:24:19.511398Z","shell.execute_reply":"2024-04-18T09:24:19.511414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loaded = AutoModel.from_pretrained(\"bert-base-uncased\")\nmodel_loaded = EmotionClassifier(model_loaded, num_classes)\nmodel_loaded = DataParallel(model_loaded)\nprint(model_loaded)\nmodel_loaded.load_state_dict(torch.load('model_weights.pth'))\nmodel_loaded.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.512547Z","iopub.status.idle":"2024-04-18T09:24:19.512883Z","shell.execute_reply.started":"2024-04-18T09:24:19.512712Z","shell.execute_reply":"2024-04-18T09:24:19.512725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_encodings = tokenizer(\"I am done with you\", truncation=True, \n                            padding=True, max_length=128, \n                            return_tensors='pt')\n\ninputs = {'input_ids': input_encodings['input_ids'].to(device),\n          'attention_mask': input_encodings['attention_mask'].to(device)}\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.513958Z","iopub.status.idle":"2024-04-18T09:24:19.514299Z","shell.execute_reply.started":"2024-04-18T09:24:19.514124Z","shell.execute_reply":"2024-04-18T09:24:19.514138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loaded.eval()\nwith torch.no_grad():\n    outputs = model_loaded(**inputs)\nlogits = outputs[0]\nprobabilities = torch.nn.functional.softmax(logits, dim=-1)\npredicted_label_index = torch.argmax(probabilities)\npredicted_label_index.item()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.515288Z","iopub.status.idle":"2024-04-18T09:24:19.515610Z","shell.execute_reply.started":"2024-04-18T09:24:19.515451Z","shell.execute_reply":"2024-04-18T09:24:19.515464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sadness (0), joy (1), love (2), anger (3), fear (4), and surprise (5)","metadata":{}},{"cell_type":"markdown","source":"# GoEmotions","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ngoemotions_data = pd.read_csv('/kaggle/input/goemotions-7-emotions/goemotions.csv')\ngoemotions_data.label.value_counts()\n\ntrain_X, val_X, train_y, val_y = train_test_split(goemotions_data[\"text\"], \n                                                  goemotions_data[\"label\"], \n                                                  test_size=0.2, \n                                                  random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.516385Z","iopub.status.idle":"2024-04-18T09:24:19.517518Z","shell.execute_reply.started":"2024-04-18T09:24:19.517333Z","shell.execute_reply":"2024-04-18T09:24:19.517350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport torch\nfrom torch.nn.parallel import DataParallel\nfrom sklearn.model_selection import train_test_split\n\ndef create_dataloader(df, tokenizer):\n    train_X, val_X, train_y, val_y = train_test_split(df[\"text\"], \n                                                      df[\"label\"], \n                                                      test_size=0.2, \n                                                      random_state=42)\n    train_X = train_X.tolist()\n    val_X = val_X.tolist()\n    train_y = np.array(train_y, dtype=np.float64)\n    val_y = np.array(val_y, dtype=np.float64)\n    train_encodings = tokenizer(train_X, truncation=True, \n                                padding=True, max_length=128, \n                                return_tensors='pt')\n    val_encodings = tokenizer(val_X, truncation=True, \n                              padding=True, max_length=128, \n                              return_tensors='pt')\n    train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'],\n                                                  train_encodings['attention_mask'],\n                                                  torch.tensor(train_y, dtype=torch.float64))\n    val_dataset = torch.utils.data.TensorDataset(val_encodings['input_ids'],\n                                                val_encodings['attention_mask'],\n                                                torch.tensor(val_y, dtype=torch.float64))\n    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, batch_size=32)\n    return train_dataloader, val_dataloader\n\nclass Classifier(torch.nn.Module):\n    def __init__(self, transformer_model, num_classes):\n        super(Classifier, self).__init__()\n        self.transformer = transformer_model\n        self.fc = torch.nn.Linear(768, num_classes)  \n        \n    def forward(self, input_ids, attention_mask):\n        output = self.transformer(input_ids=input_ids, \n                                  attention_mask=attention_mask)\n        pooled_output = output.pooler_output \n        logits = self.fc(pooled_output)\n        return logits\n    \ndef train_model(df):\n    \n    model = AutoModel.from_pretrained(\"bert-base-uncased\")\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n    \n    train_dataloader, val_dataloader = create_dataloader(df, tokenizer)\n    num_classes = 7\n    num_epochs = 3\n    learning_rate = 1e-5\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    model = Classifier(model, num_classes)\n    model = DataParallel(model)\n    model = model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n        total_correct = 0\n\n        # Training loop\n        print(f\"Training Epoch {epoch+1}\")\n        for i, batch in enumerate(train_dataloader):\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n\n            labels = labels.to(device).long()\n            outputs = outputs.float()\n\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total_correct += (predicted == labels).sum().item()\n\n            if (i % len(train_dataloader.dataset) * 100) % 10 == 0:\n                print(f\"{(i % len(train_dataloader.dataset) * 100):02d}% complete  |  Batch {i:4d}  |  Loss {loss.item():.4f}\")\n\n        train_loss = total_loss / len(train_dataloader)\n        train_accuracy = total_correct / len(train_dataset)\n\n        # Validation loop\n        model.eval()\n        total_val_loss = 0.0\n        total_val_correct = 0\n        val_predicted = []\n        val_labels = []\n\n        print(f\"Validation Epoch {epoch+1}\")\n        with torch.no_grad():\n            for i, batch in enumerate(val_dataloader):\n                input_ids, attention_mask, labels = batch\n                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n                outputs = g_model(input_ids, attention_mask)\n                labels = labels.to(device).long()\n\n                outputs = outputs.float()\n                loss = criterion(outputs, labels)\n\n                total_val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total_val_correct += (predicted == labels).sum().item()\n                val_predicted.extend(predicted.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n                if (i % len(val_dataloader.dataset) * 100) % 10 == 0:\n                    print(f\"{(i % len(train_dataloader.dataset) * 100):02d}% complete  |  Batch {i:4d}  |  Loss {loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.518671Z","iopub.status.idle":"2024-04-18T09:24:19.519005Z","shell.execute_reply.started":"2024-04-18T09:24:19.518835Z","shell.execute_reply":"2024-04-18T09:24:19.518856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    g_model.train()\n    total_loss = 0.0\n    total_correct = 0\n    \n    # Training loop\n    print(f\"----- Epoch {epoch+1} [Training] -----\")\n    for i, batch in enumerate(train_dataloader):\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = g_model(input_ids, attention_mask)\n       \n        labels = labels.to(device).long()\n        outputs = outputs.float()\n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total_correct += (predicted == labels).sum().item()\n        \n        if i % 100 == 0:\n            print(f\"Batch: {i:4d}  ->  Loss: {loss.item():.4f}\")\n    \n    train_loss = total_loss / len(train_dataloader)\n    train_accuracy = total_correct / len(train_dataset)\n    \n    # Validation loop\n    g_model.eval()\n    total_val_loss = 0.0\n    total_val_correct = 0\n    val_predicted = []\n    val_labels = []\n\n    print(f\"----- Epoch {epoch+1} [Validation] -----\")\n    with torch.no_grad():\n        for i, batch in enumerate(val_dataloader):\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            outputs = g_model(input_ids, attention_mask)\n            labels = labels.to(device).long()\n\n            outputs = outputs.float()\n            loss = criterion(outputs, labels)\n\n            total_val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total_val_correct += (predicted == labels).sum().item()\n            val_predicted.extend(predicted.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n            \n            if i % 100 == 0:\n                print(f\"Batch: {i:3d}  ->  Loss: {loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.520333Z","iopub.status.idle":"2024-04-18T09:24:19.520868Z","shell.execute_reply.started":"2024-04-18T09:24:19.520578Z","shell.execute_reply":"2024-04-18T09:24:19.520600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nval_predicted = np.array(val_predicted)\nval_labels = np.array(val_labels)\n\nprint(classification_report(val_labels, val_predicted, target_names = [f'Class {i}' for i in range(num_classes)]))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.522706Z","iopub.status.idle":"2024-04-18T09:24:19.523203Z","shell.execute_reply.started":"2024-04-18T09:24:19.522951Z","shell.execute_reply":"2024-04-18T09:24:19.522971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Augmentation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n!pip -qq install nltk\nimport nltk\nnltk.download('stopwords')\nimport random\n!pip -qq install spacy_udpipe\nimport spacy_udpipe\nimport re\n!pip -qq install tqdm\nfrom tqdm.notebook import tqdm_notebook as tqdm\n!pip -qq install gensim\nimport gensim","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:26:08.540793Z","iopub.execute_input":"2024-04-18T09:26:08.541456Z","iopub.status.idle":"2024-04-18T09:26:58.109896Z","shell.execute_reply.started":"2024-04-18T09:26:08.541395Z","shell.execute_reply":"2024-04-18T09:26:58.108436Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Random swap","metadata":{}},{"cell_type":"code","source":"def random_swap(words, n):\n    new_words = words.copy()\n    for _ in range(n):\n        new_words = swap_word(new_words)\n    return new_words\n\ndef swap_word(new_words):\n    random_idx_1 = random.randint(0, len(new_words) - 1)\n    random_idx_2 = random_idx_1\n    counter = 0\n    while random_idx_2 == random_idx_1:\n        random_idx_2 = random.randint(0, len(new_words) - 1)\n        counter += 1\n        if counter > 3:\n            return new_words\n    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n    return new_words","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:18.341396Z","iopub.execute_input":"2024-04-18T09:27:18.341916Z","iopub.status.idle":"2024-04-18T09:27:18.350342Z","shell.execute_reply.started":"2024-04-18T09:27:18.341860Z","shell.execute_reply":"2024-04-18T09:27:18.349186Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Random insertion","metadata":{}},{"cell_type":"code","source":"def random_insertion(words, n):\n    new_words = words.copy()\n    for _ in range(n):\n            add_word(new_words)\n    return new_words\n\ndef add_word(new_words):\n    synonyms = []\n    counter = 0\n\n    while len(synonyms) <1:\n        random_word = new_words[random.randint(0, len(new_words)-1)]\n        #synonyms = self.synonyms_cadidates(random_word, self.df)\n        synonyms = list(get_synonyms_vec(random_word))\n        counter += 1\n        if counter > 10:\n            return\n\n    random_synonym = synonyms[0]\n    random_idx = random.randint(0, len(new_words)-1)\n    new_words.insert(random_idx, random_synonym)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:18.509659Z","iopub.execute_input":"2024-04-18T09:27:18.510111Z","iopub.status.idle":"2024-04-18T09:27:18.518825Z","shell.execute_reply.started":"2024-04-18T09:27:18.510078Z","shell.execute_reply":"2024-04-18T09:27:18.517248Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Random deletion","metadata":{}},{"cell_type":"code","source":"def random_deletion(words, p):\n    \"\"\"\n    Randomly delete words from a sentence with probability p\n    :param words:\n    :param p:\n    :return:\n    \"\"\"\n    #obviously, if there's only one word, don't delete it\n    if len(words) == 1:\n        return words\n\n    #randomly delete words with probability p\n    new_words = []\n\n    for word in words:\n        r = random.uniform(0, 1) # random number between 0.0 and 1.0\n        if r > p: #kinda elegant when you think about it\n            new_words.append(word)\n\n    #if you end up deleting all words, just return a random word\n    if len(new_words) == 0:\n        rand_int = random.randint(0, len(words)-1)\n        return [words[rand_int]]\n\n    return new_words","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:18.919567Z","iopub.execute_input":"2024-04-18T09:27:18.920029Z","iopub.status.idle":"2024-04-18T09:27:18.928568Z","shell.execute_reply.started":"2024-04-18T09:27:18.919997Z","shell.execute_reply":"2024-04-18T09:27:18.926915Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Random Replacement (Vector-based)","metadata":{}},{"cell_type":"code","source":"stop_words = list(set(nltk.corpus.stopwords.words('english')))\ndef synonym_replacement_vec(words, n):\n    \n    new_words = words.copy()\n    random_word_list = list(set([word for word in words if word not in stop_words]))\n    random.shuffle(random_word_list)\n    num_replaced = 0\n    for random_word in random_word_list:\n        synonyms = get_synonyms_vec(random_word)\n        if len(synonyms) >= 1:\n            synonym = random.choice(list(synonyms))\n            new_words = [synonym if word.lower() == random_word else word for word in new_words]\n            # print(\"replaced\", random_word, \"with\", synonym)\n            num_replaced += 1\n        if num_replaced >= n:  # only replace up to n words\n            break\n\n    # this is stupid but we need it, trust me\n    sentence = ' '.join(new_words)\n    new_words = sentence.split(' ')\n    \n    return new_words\n\n############################################\nwv_from_text = gensim.models.KeyedVectors.load_word2vec_format('/kaggle/working/word2vec_goemotions_300dim.txt', \n                                                 binary=False)\n\ndef get_synonyms_vec(word):\n    \n    synonyms = set()\n    flag = False\n    vec = None\n    try:\n        vec = wv_from_text.similar_by_word(word.lower())\n    except KeyError:\n        flag = True\n        pass\n\n    if flag is False:\n        synonyms.add(vec[0][0])\n\n    if word in synonyms:\n        synonyms.remove(word)\n\n    return synonyms","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:19.159413Z","iopub.execute_input":"2024-04-18T09:27:19.159795Z","iopub.status.idle":"2024-04-18T09:27:24.774516Z","shell.execute_reply.started":"2024-04-18T09:27:19.159767Z","shell.execute_reply":"2024-04-18T09:27:24.773328Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation","metadata":{}},{"cell_type":"code","source":"def augmentation(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, alpha_rd=0.1, num_aug=9):\n    \"\"\"\n    @param sentence\n    @param alpha_sr synonym replacement rate, percentage of the total sentence\n    @param alpha_ri random insertion rate, percentage of the total sentence\n    @param alpha_rs random swap rate, percentage of the total sentence\n    @param alpha_rd random deletion rate, percentage of the total sentence\n    @param num_aug how many augmented sentences to create\n\n    @return list of augmented sentences\n    \"\"\"\n    words_list = sentence.split(' ')  # list of words in the sentence\n    words = [word for word in words_list if word != '']  # remove empty words\n    num_words = len(words_list)  # number of words in the sentence\n\n    augmented_sentences = []\n    num_new_per_technique = int(num_aug / 4) + 1 # number of augmented sentences per technique\n \n    #synonmym replacement\n    if (alpha_sr > 0):\n        n_sr = max(1, int(alpha_sr * num_words)) # number of words to be replaced per technique\n        #print(\"Number of words to be replaced per technique: \", n_sr)\n        for _ in range(num_new_per_technique):\n            a_words = synonym_replacement_vec(words, n_sr)\n            augmented_sentences.append(' '.join(a_words))\n    #random insertion\n    if (alpha_ri > 0):\n        n_ri = max(1,int(alpha_ri * num_words))\n        for _ in range(num_new_per_technique):\n            a_words = random_insertion(words, n_ri)\n            augmented_sentences.append(' '.join(a_words))\n    #Random Deletion\n    if (alpha_rd > 0):\n        for _ in range(num_new_per_technique):\n            a_words = random_deletion(words, alpha_rd)\n            augmented_sentences.append(' '.join(a_words))\n    #Random Swap\n    if (alpha_rs > 0):\n        n_rs = max(1, int(alpha_rs * num_words))\n        for _ in range(num_new_per_technique):\n            a_words = random_swap(words, n_rs)\n            augmented_sentences.append(' '.join(a_words))\n\n    return augmented_sentences","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:24.780078Z","iopub.execute_input":"2024-04-18T09:27:24.780513Z","iopub.status.idle":"2024-04-18T09:27:24.792454Z","shell.execute_reply.started":"2024-04-18T09:27:24.780479Z","shell.execute_reply":"2024-04-18T09:27:24.791005Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def create_encodings(df):\n    texts = [gensim.utils.simple_preprocess(text) for text in df.text]\n    words = [word.encode('utf-8') for words in texts for word in words]\n    # Training Word2Vec model\n    w2v_model = gensim.models.Word2Vec(texts, min_count=1, vector_size=300)\n    # Save Model \n    w2v_model.wv.save_word2vec_format('word2vec_goemotions_300dim.txt', binary=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:24.794469Z","iopub.execute_input":"2024-04-18T09:27:24.794998Z","iopub.status.idle":"2024-04-18T09:27:24.808559Z","shell.execute_reply.started":"2024-04-18T09:27:24.794950Z","shell.execute_reply":"2024-04-18T09:27:24.807302Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def create_augmented_df(df, sr, ri, rs, rd, n):\n    aug_data = {0:[],1:[],2:[],3:[],4:[],5:[],6:[]}\n    n_sentences = df.shape[0]\n    tqdm.pandas(desc=\"Augmentation Progress \")\n    df['augmented'] = df.text.progress_apply(lambda x: augmentation(x, \n                                                           alpha_sr=0.3, alpha_ri=0.2, \n                                                           alpha_rs=0.4, alpha_rd=0.3, \n                                                           num_aug=4))\n    aug_df = df[['augmented','label']].rename(columns={'augmented':'text'})\n    aug_df = aug_df.explode('text', ignore_index=True)\n    aug_df.to_csv(f\"goemotions_aug_{sr}_{ri}_{rs}_{rd}_{n}.csv\")\n    return aug_df\n\ndef sample_df(df, n_rows=None):\n    n_rows = df.label.value_counts().min() if n_rows == None else n_rows\n    def sample_rows(group, x):\n        if group.shape[0] > x:\n            return group.sample(x)\n        else:\n            return group\n    \n    sampled_df = df.groupby('label')[['label','text']].apply(lambda group: sample_rows(group, n_rows))\n    return sampled_df","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:24.811047Z","iopub.execute_input":"2024-04-18T09:27:24.811512Z","iopub.status.idle":"2024-04-18T09:27:24.828251Z","shell.execute_reply.started":"2024-04-18T09:27:24.811476Z","shell.execute_reply":"2024-04-18T09:27:24.827233Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"goemotions = pd.read_csv(\"/kaggle/input/goemotions-7-emotions/goemotions.csv\")\nprint(f\"Original dataset: {goemotions.shape}\")\ncreate_encodings(goemotions) # Create Word2Vec embeddings\ngoemotions = sample_df(goemotions)\nprint(f\"Sampled dataset: {goemotions.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:24.829465Z","iopub.execute_input":"2024-04-18T09:27:24.830225Z","iopub.status.idle":"2024-04-18T09:27:37.786034Z","shell.execute_reply.started":"2024-04-18T09:27:24.830177Z","shell.execute_reply":"2024-04-18T09:27:37.784853Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Original dataset: (54263, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20c42af877804679aca15ef1f9f70d5b"}},"metadata":{}},{"name":"stdout","text":"Sampled dataset: (5166, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"goemotions_aug_1 = create_augmented_df(goemotions, .3, .2, .4, .3, 4)\nprint(f\"Augmented dataset: {goemotions_aug_1.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:27:50.801225Z","iopub.execute_input":"2024-04-18T09:27:50.801702Z","iopub.status.idle":"2024-04-18T09:30:39.170644Z","shell.execute_reply.started":"2024-04-18T09:27:50.801669Z","shell.execute_reply":"2024-04-18T09:30:39.169369Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Augmentation Progress :   0%|          | 0/5166 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036afd4404c94178bb11f1b3d96cb097"}},"metadata":{}},{"name":"stdout","text":"Augmented dataset: (41328, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training BERT","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport torch\nfrom torch.nn.parallel import DataParallel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tqdm.notebook import tqdm_notebook\n\ndef create_dataloader(df, tokenizer):\n    train_X, val_X, train_y, val_y = train_test_split(df[\"text\"], \n                                                      df[\"label\"], \n                                                      test_size=0.2, \n                                                      random_state=42)\n    train_X = train_X.tolist()\n    val_X = val_X.tolist()\n    train_y = np.array(train_y, dtype=np.float64)\n    val_y = np.array(val_y, dtype=np.float64)\n    train_encodings = tokenizer(train_X, truncation=True, \n                                padding=True, max_length=128, \n                                return_tensors='pt')\n    val_encodings = tokenizer(val_X, truncation=True, \n                              padding=True, max_length=128, \n                              return_tensors='pt')\n    train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'],\n                                                  train_encodings['attention_mask'],\n                                                  torch.tensor(train_y, dtype=torch.float64))\n    val_dataset = torch.utils.data.TensorDataset(val_encodings['input_ids'],\n                                                val_encodings['attention_mask'],\n                                                torch.tensor(val_y, dtype=torch.float64))\n    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, batch_size=32)\n    return train_dataloader, val_dataloader\n\nclass Classifier(torch.nn.Module):\n    def __init__(self, transformer_model, num_classes):\n        super(Classifier, self).__init__()\n        self.transformer = transformer_model\n        self.fc = torch.nn.Linear(768, num_classes)  \n        \n    def forward(self, input_ids, attention_mask):\n        output = self.transformer(input_ids=input_ids, \n                                  attention_mask=attention_mask)\n        pooled_output = output.pooler_output \n        logits = self.fc(pooled_output)\n        return logits\n    \ndef train_model(df):\n    \n    model = AutoModel.from_pretrained(\"bert-base-uncased\")\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n    \n    train_dataloader, val_dataloader = create_dataloader(df, tokenizer)\n    num_classes = 7\n    num_epochs = 3\n    learning_rate = 1e-5\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    model = Classifier(model, num_classes)\n    model = DataParallel(model)\n    model = model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = torch.nn.CrossEntropyLoss()\n    \n    for epoch in tqdm_notebook(range(num_epochs)):\n        model.train()\n        total_loss = 0.0\n        total_correct = 0\n\n        # Training loop\n        print(f\"Training Epoch {epoch+1}\")\n        for batch in tqdm_notebook(train_dataloader):\n            input_ids, attention_mask, labels = batch\n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n\n            labels = labels.to(device).long()\n            outputs = outputs.float()\n\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total_correct += (predicted == labels).sum().item()\n\n#             if i  % 50 == 0:\n#                 print(f\"Batch {i:4d}  |  Loss {loss.item():.4f}\")\n\n        train_loss = total_loss / len(train_dataloader)\n        train_accuracy = total_correct / len(train_dataloader.dataset)\n\n        # Validation loop\n        model.eval()\n        total_val_loss = 0.0\n        total_val_correct = 0\n        val_predicted = []\n        val_labels = []\n\n        print(f\"Validation Epoch {epoch+1}\")\n        with torch.no_grad():\n            for batch in tqdm_notebook(val_dataloader):\n                input_ids, attention_mask, labels = batch\n                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n                outputs = model(input_ids, attention_mask)\n                labels = labels.to(device).long()\n\n                outputs = outputs.float()\n                loss = criterion(outputs, labels)\n\n                total_val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total_val_correct += (predicted == labels).sum().item()\n                val_predicted.extend(predicted.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n#                 if i % 50 == 0:\n#                     print(f\"Batch {i:4d}  |  Loss {loss.item():.4f}\")\n                    \n    val_predicted = np.array(val_predicted)\n    val_labels = np.array(val_labels)\n\n    print(classification_report(val_labels, val_predicted, target_names = [f'Class {i}' for i in range(num_classes)]))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:44:13.679129Z","iopub.execute_input":"2024-04-18T09:44:13.680670Z","iopub.status.idle":"2024-04-18T09:44:13.706154Z","shell.execute_reply.started":"2024-04-18T09:44:13.680611Z","shell.execute_reply":"2024-04-18T09:44:13.704557Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Baseline\ngoemotions = pd.read_csv(\"/kaggle/input/goemotions-7-emotions/goemotions.csv\")\n# Augmented\ngoemotions_aug = pd.read_csv(\"/kaggle/working/goemotions_aug_0.3_0.2_0.4_0.3_4.csv\")\ngoemotions_aug = goemotions_aug.rename(columns={'augmented':'text'})","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:31:08.899883Z","iopub.execute_input":"2024-04-18T09:31:08.900675Z","iopub.status.idle":"2024-04-18T09:31:09.113933Z","shell.execute_reply.started":"2024-04-18T09:31:08.900633Z","shell.execute_reply":"2024-04-18T09:31:09.112870Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_model(goemotions)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:24:19.553202Z","iopub.status.idle":"2024-04-18T09:24:19.553759Z","shell.execute_reply.started":"2024-04-18T09:24:19.553392Z","shell.execute_reply":"2024-04-18T09:24:19.553407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_model(goemotions_aug)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:44:18.203705Z","iopub.execute_input":"2024-04-18T09:44:18.204154Z","iopub.status.idle":"2024-04-18T09:46:25.995521Z","shell.execute_reply.started":"2024-04-18T09:44:18.204118Z","shell.execute_reply":"2024-04-18T09:46:25.993504Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a19b12ba5ae2495c8e2a44fbfaee96b2"}},"metadata":{}},{"name":"stdout","text":"Training Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1034 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f606571c75bd4c438ca1b395c04bd2d1"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoemotions_aug\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[31], line 79\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     76\u001b[0m input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device), attention_mask\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 79\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     82\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mfloat()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:167\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataParallel.forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids:\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mbuffers()):\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[31], line 42\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[0;32m---> 42\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mpooler_output \n\u001b[1;32m     45\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(pooled_output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    536\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    537\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 539\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:451\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 451\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}